# =========================
# STEP 1: Install Dependencies
# =========================
!pip install -q ultralytics kagglehub

# =========================
# STEP 2: Authenticate with KaggleHub & Download Dataset
# =========================
import kagglehub
import os
import shutil
import json
from PIL import Image

# kagglehub.login()  # Uncomment if login is needed
dataset_path = kagglehub.dataset_download("solesensei/solesensei_bdd100k")
print("Path to dataset files:", dataset_path)

print(f"\nInspecting dataset directory: {dataset_path}")
try:
    for item in os.listdir(dataset_path):
        print(f"  {item}")
except Exception as e:
    print(f"Error listing contents: {e}")

# =========================
# UPDATE PATHS (verify these from your inspection)
# =========================
bdd_root_download = dataset_path
output_root = "/content/working/yolo_bdd100k"

image_dir_train = os.path.join(bdd_root_download, "bdd100k", "bdd100k", "images", "100k", "train")
image_dir_val = os.path.join(bdd_root_download, "bdd100k", "bdd100k", "images", "100k", "val")
labels_json_train = os.path.join(bdd_root_download, "bdd100k_labels_release", "bdd100k", "labels", "bdd100k_labels_images_train.json")
labels_json_val = os.path.join(bdd_root_download, "bdd100k_labels_release", "bdd100k", "labels", "bdd100k_labels_images_val.json")

train_img_out = os.path.join(output_root, "images", "train")
val_img_out = os.path.join(output_root, "images", "val")
train_lbl_out = os.path.join(output_root, "labels", "train")
val_lbl_out = os.path.join(output_root, "labels", "val")

for folder in [train_img_out, val_img_out, train_lbl_out, val_lbl_out]:
    os.makedirs(folder, exist_ok=True)

# =========================
# UPDATED CLASS MAP WITH DETAILED TRAFFIC LIGHT COLORS AND SIGN TYPES
# =========================
class_map = {
    "car": 0,
    "truck": 1,
    "traffic light - red": 2,
    "traffic light - yellow": 3,
    "traffic light - green": 4,
    "traffic sign - stop": 5,
    "traffic sign - speed limit": 6,
    "traffic sign - yield": 7,
    "person": 8,
    "bike": 9,
    "bus": 10,
    "motor": 11,
}

# =========================
# Helper functions for traffic light and traffic sign detailed classes
# =========================
def get_traffic_light_class(label):
    attrs = label.get("attributes", {})
    # BDD100K uses "trafficLightColor" attribute for traffic lights
    color = attrs.get("trafficLightColor", "").lower()
    if color == "red":
        return "traffic light - red"
    elif color == "yellow":
        return "traffic light - yellow"
    elif color == "green":
        return "traffic light - green"
    else:
        return None

def get_traffic_sign_class(label):
    attrs = label.get("attributes", {})
    # Traffic sign type might be under 'signType' or 'sign_type', try both
    sign_type = attrs.get("signType", "") or attrs.get("sign_type", "")
    sign_type = sign_type.lower()
    if "stop" in sign_type:
        return "traffic sign - stop"
    elif "speed limit" in sign_type or "speedlimit" in sign_type:
        return "traffic sign - speed limit"
    elif "yield" in sign_type:
        return "traffic sign - yield"
    else:
        # fallback to generic if no specific info is found
        return None

# =========================
# Conversion function
# =========================
def convert_bdd_annotations(json_file, img_dir, out_img_dir, out_lbl_dir, class_map, subset_size=None):
    print(f"\n--- Starting conversion for {json_file} ---")

    if not os.path.exists(json_file):
        print(f"Annotation file not found: {json_file}")
        return
    if not os.path.exists(img_dir):
        print(f"Image directory not found: {img_dir}")
        return

    with open(json_file, 'r') as f:
        data = json.load(f)

    if subset_size is not None:
        data = data[:min(subset_size, len(data))]
        print(f"Processing a subset of {len(data)} annotations.")

    num_images_processed = 0
    num_images_copied = 0
    num_labels_written = 0

    for item in data:
        img_name = item["name"]
        img_path = os.path.join(img_dir, img_name)

        if not os.path.isfile(img_path):
            continue

        try:
            img = Image.open(img_path)
            width, height = img.size
        except Exception as e:
            print(f"Error opening image {img_name}: {e}")
            continue

        label_lines = []
        for label in item.get("labels", []):
            category = label.get("category")

            # Handle traffic light with color classes
            if category == "traffic light":
                cls_name = get_traffic_light_class(label)
                if cls_name is None or cls_name not in class_map:
                    continue

            # Handle traffic sign with specific meaning classes
            elif category == "traffic sign":
                cls_name = get_traffic_sign_class(label)
                if cls_name is None or cls_name not in class_map:
                    continue

            # Other categories use the existing map
            else:
                if category not in class_map:
                    continue
                cls_name = category

            box2d = label.get("box2d")
            if not box2d:
                continue

            x1, y1, x2, y2 = box2d.get("x1"), box2d.get("y1"), box2d.get("x2"), box2d.get("y2")
            if None in (x1, y1, x2, y2) or x2 <= x1 or y2 <= y1:
                continue

            # Normalize box coordinates to YOLO format
            xc = ((x1 + x2) / 2) / width
            yc = ((y1 + y2) / 2) / height
            w = (x2 - x1) / width
            h = (y2 - y1) / height

            if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                continue

            cls_id = class_map[cls_name]
            label_lines.append(f"{cls_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}")

        num_images_processed += 1

        if len(label_lines) > 0:
            dest_img_path = os.path.join(out_img_dir, img_name)
            try:
                shutil.copy(img_path, dest_img_path)
                num_images_copied += 1
            except Exception as e:
                print(f"Failed to copy image {img_name}: {e}")
                continue

            label_file = os.path.join(out_lbl_dir, img_name.replace(".jpg", ".txt"))
            try:
                with open(label_file, "w") as f:
                    f.write("\n".join(label_lines))
                num_labels_written += 1
            except Exception as e:
                print(f"Failed to write label file for {img_name}: {e}")

        if num_images_processed % 1000 == 0:
            print(f"Processed {num_images_processed} annotations, copied {num_images_copied} images.")

    print(f"\nFinished conversion for {json_file}")
    print(f"Total annotations processed: {num_images_processed}")
    print(f"Total images copied: {num_images_copied}")
    print(f"Total label files written: {num_labels_written}")
    print(f"Output images: {len(os.listdir(out_img_dir)) if os.path.exists(out_img_dir) else 0}")
    print(f"Output labels: {len(os.listdir(out_lbl_dir)) if os.path.exists(out_lbl_dir) else 0}")

# =========================
# Convert dataset
# =========================
subset_size_train = 2500
print(f"Converting training set (subset_size={subset_size_train})...")
convert_bdd_annotations(labels_json_train, image_dir_train, train_img_out, train_lbl_out, class_map, subset_size=subset_size_train)

subset_size_val = 100
print(f"\nConverting validation set (subset_size={subset_size_val})...")
convert_bdd_annotations(labels_json_val, image_dir_val, val_img_out, val_lbl_out, class_map, subset_size=subset_size_val)

# =========================
# Create dataset YAML config for YOLOv8 training
# =========================
yaml_path = os.path.join(output_root, "bdd100k.yaml")
yaml_content = f"""
path: {output_root}
train: images/train
val: images/val

nc: {len(class_map)}
names: {list(class_map.keys())}
"""
with open(yaml_path, "w") as f:
    f.write(yaml_content.strip())

print(f"\nDataset YAML config saved to: {yaml_path}")
print("Content of bdd100k.yaml:")
!cat {yaml_path}

# =========================
# STEP 6: Train YOLOv8 Model
# =========================
print("\nStarting YOLOv8 training...")
from ultralytics import YOLO

model = YOLO("yolo11n.pt")  # or any YOLOv8 variant

if not os.path.exists(train_img_out) or not os.listdir(train_img_out):
    print(f"\n[ERROR] No training images found at {train_img_out}, aborting training.")
else:
    print(f"Found {len(os.listdir(train_img_out))} training images.")
    model.train(data=yaml_path, epochs=100, imgsz=640, batch=8)

# =========================
# STEP 7: Inference & Display
# =========================
print("\nPerforming inference on a sample image...")
from IPython.display import Image, display

if os.path.exists(train_img_out) and os.listdir(train_img_out):
    sample_image_filename = os.listdir(train_img_out)[0]
    sample_image_path = os.path.join(train_img_out, sample_image_filename)

    if os.path.exists(sample_image_path):
        print(f"Running inference on: {sample_image_path}")
        results = model(sample_image_path, save=True, conf=0.4)

        if results and hasattr(results[0], 'save_dir'):
            output_dir = results[0].save_dir
            pred_image_path = os.path.join(output_dir, sample_image_filename)

            if os.path.exists(pred_image_path):
                display(Image(filename=pred_image_path))
            else:
                print(f"Prediction image not found at {pred_image_path}")
        else:
            print("Could not determine inference results directory.")
    else:
        print(f"Sample image not found: {sample_image_path}")
else:
    print(f"No images available for inference in {train_img_out}")
